{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import config as creds\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "from numpy.random import randn\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ELECTRICITY for years 2018-2019, INDIVIDUAL BUILDING TYPES \n",
    "Foreign keys: One Hot encode categorical features YEARBUILT and WARD, exclude DCREALPROPERTYID  \n",
    "Numeric features: sqft, awnd, cldd, htdd, snow\n",
    "Target feature: kbtu\n",
    "VotingRegressor - \"Parking, zero instances\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONNECT TO DATABASE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected\n",
      "Cursor created\n"
     ]
    }
   ],
   "source": [
    "user=creds.PGUSER\n",
    "password=creds.PGPASSWORD\n",
    "host=creds.PGHOST\n",
    "port=5432\n",
    "database=creds.PGDATABASE\n",
    "\n",
    "engine_str=f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\"\n",
    "engine = create_engine(engine_str)\n",
    "conn = engine.raw_connection()\n",
    "print('Connected')\n",
    "cur = conn.cursor()\n",
    "print('Cursor created')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXTRACT DATASET:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kbtu</th>\n",
       "      <th>reportedbuildinggrossfloorarea</th>\n",
       "      <th>dcrealpropertyid</th>\n",
       "      <th>ward</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>primarypropertytype_selfselect</th>\n",
       "      <th>elegas</th>\n",
       "      <th>awnd</th>\n",
       "      <th>cldd</th>\n",
       "      <th>htdd</th>\n",
       "      <th>snow</th>\n",
       "      <th>tavg</th>\n",
       "      <th>wdf2</th>\n",
       "      <th>wdf5</th>\n",
       "      <th>wsf2</th>\n",
       "      <th>wsf5</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [kbtu, reportedbuildinggrossfloorarea, dcrealpropertyid, ward, yearbuilt, primarypropertytype_selfselect, elegas, awnd, cldd, htdd, snow, tavg, wdf2, wdf5, wsf2, wsf5, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query='''\n",
    "SELECT b.kbtu\n",
    "      ,b.REPORTEDBUILDINGGROSSFLOORAREA\n",
    "      ,b.dcrealpropertyid\n",
    "      ,b.ward\n",
    "      ,b.yearbuilt\n",
    "      ,b.primarypropertytype_selfselect\n",
    "      ,b.elegas\n",
    "      ,n.awnd\n",
    "      ,n.cldd\n",
    "      ,n.htdd\n",
    "      ,n.snow\n",
    "      ,n.tavg\n",
    "      ,n.wdf2\n",
    "      ,n.wdf5\n",
    "      ,n.wsf2\n",
    "      ,n.wsf5\n",
    "      ,n.date \n",
    "FROM buildings_data b\n",
    "LEFT OUTER join noaa_data n\n",
    "ON b.REPORTINGYEAR = n.WEATHERYEAR\n",
    "WHERE b.MONTH = n.MONTH\n",
    "AND b.ELEGAS = 'E'\n",
    "AND b.PRIMARYPROPERTYTYPE_SELFSELECT = '12'\n",
    "AND b.REPORTINGYEAR BETWEEN 2018 AND 2019\n",
    "AND b.YEARBUILT > 0\n",
    "AND b.REPORTEDBUILDINGGROSSFLOORAREA > 50000;\n",
    "'''\n",
    "\n",
    "data=pd.read_sql(query,conn)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FORMAT COLUMNS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONVERT 'Date' COLUMN TO datetime format\n",
    "\n",
    "#data[\"reportingyear\"] = data[\"reportingyear\"].astype(str)\n",
    "#data['month']=data['month'].apply(lambda x: '{0:0>2}'.format(x))\n",
    "#data['date_time'] = data[['reportingyear', 'month']].agg('-'.join, axis=1)\n",
    "#data['date_time'] = (data.date_time + \"-01\")\n",
    "#data['date_time'] = datetime.strptime('date_time', \"%Y-%m-%d\")\n",
    "data['datetime']=pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['primarypropertytype_selfselect'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['primarypropertytype_selfselect']=data['primarypropertytype_selfselect'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kbtu</th>\n",
       "      <th>reportedbuildinggrossfloorarea</th>\n",
       "      <th>dcrealpropertyid</th>\n",
       "      <th>ward</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>primarypropertytype_selfselect</th>\n",
       "      <th>elegas</th>\n",
       "      <th>awnd</th>\n",
       "      <th>cldd</th>\n",
       "      <th>htdd</th>\n",
       "      <th>snow</th>\n",
       "      <th>tavg</th>\n",
       "      <th>wdf2</th>\n",
       "      <th>wdf5</th>\n",
       "      <th>wsf2</th>\n",
       "      <th>wsf5</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [kbtu, reportedbuildinggrossfloorarea, dcrealpropertyid, ward, yearbuilt, primarypropertytype_selfselect, elegas, awnd, cldd, htdd, snow, tavg, wdf2, wdf5, wsf2, wsf5, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.set_index('datetime', inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['kbtu', 'reportedbuildinggrossfloorarea', 'dcrealpropertyid', 'ward',\n",
       "       'yearbuilt', 'primarypropertytype_selfselect', 'elegas', 'awnd', 'cldd',\n",
       "       'htdd', 'snow', 'tavg', 'wdf2', 'wdf5', 'wsf2', 'wsf5', 'date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kbtu                              object\n",
       "reportedbuildinggrossfloorarea    object\n",
       "dcrealpropertyid                  object\n",
       "ward                              object\n",
       "yearbuilt                         object\n",
       "primarypropertytype_selfselect     int32\n",
       "elegas                            object\n",
       "awnd                              object\n",
       "cldd                              object\n",
       "htdd                              object\n",
       "snow                              object\n",
       "tavg                              object\n",
       "wdf2                              object\n",
       "wdf5                              object\n",
       "wsf2                              object\n",
       "wsf5                              object\n",
       "date                              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation fmin which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-d1a2e93c4b5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mftr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"kbtu\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"reportedbuildinggrossfloorarea\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ward\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"yearbuilt\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"awnd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cldd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"htdd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"snow\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcorrMatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mftr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrMatrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'.1f'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36mheatmap\u001b[0;34m(data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, linewidths, linecolor, cbar, cbar_kws, cbar_ax, square, xticklabels, yticklabels, mask, ax, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m     \"\"\"\n\u001b[1;32m    544\u001b[0m     \u001b[0;31m# Initialize the plotter object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m     plotter = _HeatMapper(data, vmin, vmax, cmap, center, robust, annot, fmt,\n\u001b[0m\u001b[1;32m    546\u001b[0m                           \u001b[0mannot_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcbar_kws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxticklabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m                           yticklabels, mask)\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, vmin, vmax, cmap, center, robust, annot, fmt, annot_kws, cbar, cbar_kws, xticklabels, yticklabels, mask)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;31m# Determine good default values for the colormapping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         self._determine_cmap_params(plot_data, vmin, vmax,\n\u001b[0m\u001b[1;32m    166\u001b[0m                                     cmap, center, robust)\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/seaborn/matrix.py\u001b[0m in \u001b[0;36m_determine_cmap_params\u001b[0;34m(self, plot_data, vmin, vmax, cmap, center, robust)\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanpercentile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mvmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalc_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmin\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/lib/python3.8/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;31m# Fast, but not safe for subclasses of ndarray, or object arrays,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;31m# which do not implement isnan (gh-9009), or fmin correctly (gh-8975)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             warnings.warn(\"All-NaN slice encountered\", RuntimeWarning,\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation fmin which has no identity"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1080 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(25,15))\n",
    "ftr = list([\"kbtu\", \"reportedbuildinggrossfloorarea\", \"ward\", \"yearbuilt\", \"awnd\", \"cldd\", \"htdd\", \"snow\"])\n",
    "corrMatrix = data[ftr].corr()\n",
    "sns.heatmap(corrMatrix, annot=True, fmt='.1f', linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DEFINE FEATURES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"kbtu\"\n",
    "COLS = ['reportedbuildinggrossfloorarea', 'ward', 'yearbuilt', 'awnd', 'cldd', 'htdd', 'snow', 'datetime']\n",
    "\n",
    "def make_sklearn_data(df=data, target=TARGET, cols=COLS):\n",
    "    df = df.reset_index()\n",
    "    X, y = df[cols], df[target]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['reportedbuildinggrossfloorarea', 'ward', 'yearbuilt', 'awnd', 'cldd', 'htdd', 'snow']\n",
    "X, y = make_sklearn_data(cols=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rank2D\n",
    "from yellowbrick.features import Rank2D\n",
    "\n",
    "# Instantiate the visualizer with the Pearson ranking algorithm\n",
    "visualizer = Rank2D(algorithm='pearson', features=features, size=(1080, 720))\n",
    "\n",
    "visualizer.fit(X, y)\n",
    "visualizer.transform(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the visualizer with the Covariance algorithm\n",
    "visualizer = Rank2D(algorithm='covariance', features=features, size=(1080, 720))\n",
    "\n",
    "visualizer.fit(X, y)\n",
    "visualizer.transform(X)\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "import yellowbrick as yb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from yellowbrick.features import RadViz\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=10)\n",
    "viz = FeatureImportances(model, labels=features, size=(1080, 720))\n",
    "\n",
    "viz.fit(X, y)\n",
    "# Note: the FeatureImportances visualizer is a model visualizer,\n",
    "# not a feature visualizer, so it doesn't have a transform method!\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importances\n",
    "import yellowbrick as yb\n",
    "from sklearn.linear_model import Lasso\n",
    "from yellowbrick.features import RadViz\n",
    "from yellowbrick.features import FeatureImportances\n",
    "\n",
    "\n",
    "model = Lasso()\n",
    "viz = FeatureImportances(model, labels=features, size=(1080, 720))\n",
    "\n",
    "viz.fit(X, y)\n",
    "# Note: the FeatureImportances visualizer is a model visualizer,\n",
    "# not a feature visualizer, so it doesn't have a transform method!\n",
    "viz.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CYCLIC ENCODER:  to capture temporal cycles (yearly).\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CyclicEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, date_extract=\"month\"):\n",
    "        if date_extract not in {\"minute\", \"hour\", \"week\", \"month\", \"year\"}:\n",
    "            raise ValueError(f\"specify correct date component to extract, not {date_extract}\")\n",
    "        self.date_extract = date_extract\n",
    "    \n",
    "    def get_date_component(self, x):\n",
    "        if self.date_extract == \"month\":\n",
    "            return x.dt.month\n",
    "        elif self.date_extract == \"year\":\n",
    "            return x.dt.year\n",
    "        else:\n",
    "            raise NotImplementedError(f\"{self.date_extract} date component not implemented yet\")\n",
    "            \n",
    "    def fit(self, X, y=None):\n",
    "        self.cycle_max_ = self.get_date_component(X).max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X,  y=None):\n",
    "        cols = []\n",
    "        names = []\n",
    "        x = self.get_date_component(X)\n",
    "        xn = 2 * np.pi * x / self.cycle_max_\n",
    "        cols.append(np.cos(xn))\n",
    "        names.append(f\"{X.name}_cos\")\n",
    "        cols.append(np.sin(xn))\n",
    "        names.append(f\"{X.name}_sin\")\n",
    "        return pd.DataFrame(np.asarray(cols).T, columns=names)\n",
    "\n",
    "    \n",
    "ce = CyclicEncoder().fit_transform(data.reset_index()[\"datetime\"])\n",
    "ce.plot(x=\"datetime_cos\", y=\"datetime_sin\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FEATURE EXTRACTION\n",
    "from sklearn.base import clone\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "extraction = Pipeline([\n",
    "    ('column_selection', ColumnTransformer([\n",
    "        ('time_components', FeatureUnion([\n",
    "            ('month', CyclicEncoder(date_extract='month')), \n",
    "            ('year', CyclicEncoder(date_extract='year')), \n",
    "        ]), 'datetime'),\n",
    "        ('ward_one_hot', OneHotEncoder(handle_unknown='ignore'), ['ward']),\n",
    "        ('yearbuilt_one_hot', OneHotEncoder(handle_unknown='ignore'), ['yearbuilt']),\n",
    "    ], remainder=\"passthrough\")),\n",
    "])\n",
    "\n",
    "def make_energy_pipeline(model, append_transformers=None, fe=extraction):\n",
    "    pipe = clone(fe)\n",
    "    \n",
    "    if append_transformers:\n",
    "        for step in append_transformers:\n",
    "            pipe.steps.append(step)\n",
    "    \n",
    "    pipe.steps.append([\"model\", clone(model)])\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the Feature Extraction Pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "X_train, X_test, y_train, y_test = tts(*make_sklearn_data(), test_size=0.2)\n",
    "\n",
    "model = make_energy_pipeline(LinearRegression())\n",
    "model.fit(X_train, y_train)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TIME SERIES CROSS VALIDATION\n",
    "from functools import partial\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "rmse = partial(mean_squared_error, squared=False)\n",
    "\n",
    "\n",
    "def time_series_evaluate(model, X, y):\n",
    "    \"\"\"\n",
    "    Performs time series cross validation on the model, returning the\n",
    "    cross validated r2, mse, and mae of the regressor, along with the \n",
    "    final fitted model, fitted on all of the data.\n",
    "    \"\"\"\n",
    "    cv = TimeSeriesSplit(12)\n",
    "    scores = {}\n",
    "    \n",
    "    scores[\"r2\"] = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(r2_score))\n",
    "    scores[\"mse\"] = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(mean_squared_error))\n",
    "#     scores[\"rmse\"] = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(rmse))\n",
    "    scores[\"mae\"] = cross_val_score(model, X, y, cv=cv, scoring=make_scorer(mean_absolute_error))\n",
    "    \n",
    "    model.fit(X, y)\n",
    "    return model, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LINEAR MODEL\n",
    "X, y = make_sklearn_data()\n",
    "lm = make_energy_pipeline(LinearRegression())\n",
    "time_series_evaluate(lm, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second order polynomial regression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "qm = make_energy_pipeline(SGDRegressor(), [('quad', PolynomialFeatures(2))])\n",
    "time_series_evaluate(qm, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfm = make_energy_pipeline(RandomForestRegressor(n_estimators=10, max_depth=3))\n",
    "time_series_evaluate(rfm, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "r1 = LinearRegression()\n",
    "r2 = RandomForestRegressor(n_estimators=10, random_state=1)\n",
    "\n",
    "X, y = make_sklearn_data()\n",
    "er = make_energy_pipeline(VotingRegressor([('lr', r1), ('rf', r2)]))\n",
    "print(time_series_evaluate(er, X, y))\n",
    "print(\"Time = {:0.3f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "start  = time.time()\n",
    "\n",
    "X, y = make_sklearn_data()\n",
    "\n",
    "estimators = [\n",
    "    ('lr', RidgeCV()),\n",
    "    ('svr', LinearSVR(random_state=42))\n",
    "]\n",
    "\n",
    "er = make_energy_pipeline(StackingRegressor(\n",
    "    estimators=estimators,\n",
    "    final_estimator=RandomForestRegressor(n_estimators=10,\n",
    "                                          random_state=42)\n",
    "))\n",
    "print(time_series_evaluate(er, X, y))\n",
    "print(\"Time = {:0.3f} seconds\".format(time.time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()\n",
    "print('Closed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
